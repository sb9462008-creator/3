import os
import sounddevice as sd
from scipy.io.wavfile import write
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pickle

# üìÅ –§–æ–ª–¥–µ—Ä—É—É–¥ “Ø“Ø—Å–≥—ç—Ö
os.makedirs("data/audio", exist_ok=True)
os.makedirs("models", exist_ok=True)

# üéô WAV —Ñ–∞–π–ª—É—É–¥ “Ø“Ø—Å–≥—ç—Ö (—Å—É—Ä–≥–∞–ª—Ç–∞–Ω–¥ –∑–æ—Ä–∏—É–ª—Å–∞–Ω)
def generate_training_wav_files(emotions=["happy", "sad", "angry"], samples_per_emotion=3, duration=2, sr=22050):
    for emotion in emotions:
        for i in range(samples_per_emotion):
            filename = f"data/audio/{emotion}_{i+1}.wav"
            print(f"üéô [{emotion.upper()}] {i+1}-—Ä –±–∏—á–ª—ç–≥ —ç—Ö—ç–ª–ª—ç—ç...")
            audio = sd.rec(int(duration * sr), samplerate=sr, channels=1)
            sd.wait()
            write(filename, sr, audio)
            print("‚úÖ –•–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞:", filename)

# üéô –î—É—É –±–∏—á–∏—Ö (–º–∞—Å—Å–∏–≤ —Ö—ç–ª–±—ç—Ä—ç—ç—Ä)
def record_audio_array(duration=3, sr=22050):
    print("üéô –î—É—É –±–∏—á–∏–∂ –±–∞–π–Ω–∞...")
    recording = sd.rec(int(duration * sr), samplerate=sr, channels=1)
    sd.wait()
    print("‚úÖ –î—É—É –±–∏—á–∏–≥–¥–ª—ç—ç!")
    return recording

# üß© MFCC –≥–∞—Ä–≥–∞—Ö (.wav —Ñ–∞–π–ª)
def extract_mfcc_from_file(file_path, n_mfcc=40):
    try:
        audio, sr = librosa.load(file_path, res_type='kaiser_fast')
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)
        return np.mean(mfccs.T, axis=0)
    except Exception as e:
        print(f"‚ùå MFCC –≥–∞—Ä–≥–∞—Ö “Ø–µ–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞ ({file_path}):", e)
        return None

# üß© MFCC –≥–∞—Ä–≥–∞—Ö (–º–∞—Å—Å–∏–≤)
def extract_mfcc_from_array(audio, sr=22050, n_mfcc=13):
    y = np.squeeze(audio)
    y, _ = librosa.effects.trim(y)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfcc.T, axis=0).reshape(1, -1)

# üß† –ó–∞–≥–≤–∞—Ä —Å—É—Ä–≥–∞—Ö
def train_model(data_dir="data/audio", model_path="models/model.pkl"):
    features = []
    labels = []

    for file in os.listdir(data_dir):
        if file.endswith(".wav") and "_" in file and not file.startswith("recorded"):
            label = file.split("_")[0].strip().lower()
            path = os.path.join(data_dir, file)
            mfcc = extract_mfcc_from_file(path)
            if mfcc is not None and not np.isnan(mfcc).any():
                features.append(mfcc)
                labels.append(label)
            else:
                print("‚ö†Ô∏è MFCC –∞–ª–¥–∞–∞—Ç–∞–π —ç—Å–≤—ç–ª —Ö–æ–æ—Å–æ–Ω:", file)

    if len(features) < 5:
        print("‚ö†Ô∏è –°—É—Ä–≥–∞–ª—Ç —Ö–∏–π—Ö—ç–¥ —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π WAV —Ñ–∞–π–ª –∞–ª–≥–∞.")
        return None

    X = pd.DataFrame(features)
    y = pd.Series(labels)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    with open(model_path, "wb") as f:
        pickle.dump(model, f)

    print("‚úÖ –ó–∞–≥–≤–∞—Ä –∞–º–∂–∏–ª—Ç—Ç–∞–π —Å—É—Ä–ª–∞–∞:", model_path)
    return model

# üîç –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö (–º–∞—Å—Å–∏–≤)
def predict_from_array(model, features):
    probabilities = model.predict_proba(features)[0]
    emotions = model.classes_
    best_emotion = emotions[np.argmax(probabilities)]
    return emotions, probabilities, best_emotion

# üìä –í–∏–∑—É–∞–ª “Ø—Ä –¥“Ø–Ω
def plot_emotions(emotions, probabilities):
    plt.figure(figsize=(8, 4))
    plt.bar(emotions, probabilities, color='skyblue')
    plt.title("üéß –°—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–Ω –º–∞–≥–∞–¥–ª–∞–ª")
    plt.ylabel("–ú–∞–≥–∞–¥–ª–∞–ª")
    plt.ylim(0, 1)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()

# üöÄ “Æ–Ω–¥—Å—ç–Ω –≥“Ø–π—Ü—ç—Ç–≥—ç–≥—á
if __name__ == '__main__':
    # 0. WAV —Ñ–∞–π–ª—É—É–¥ “Ø“Ø—Å–≥—ç—Ö (–∞–Ω—Ö —É–¥–∞–∞ –±–æ–ª)
    generate_training_wav_files(
        emotions=["happy", "sad", "angry", "neutral"],
        samples_per_emotion=3,
        duration=3
    )

    # 1. –ó–∞–≥–≤–∞—Ä —Å—É—Ä–≥–∞—Ö
    model_path = "models/model.pkl"
    model = train_model(model_path=model_path)

    if model:
        # 2. –î—É—É –±–∏—á–∏—Ö
        audio_array = record_audio_array()

        # 3. MFCC –≥–∞—Ä–≥–∞—Ö
        features = extract_mfcc_from_array(audio_array)

        # 4. –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö
        emotions, probabilities, best_emotion = predict_from_array(model, features)

        # 5. “Æ—Ä –¥“Ø–Ω —Ö—ç–≤–ª—ç—Ö
        print("\nüéß –¢–∞–Ω–∞–π –¥—É—É —Ö–æ–æ–ª–æ–π–Ω —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª–∏–π–Ω —Ö—É–≤–∞–∞—Ä—å:")
        for emo, prob in zip(emotions, probabilities):
            print(f"  {emo.upper():<8}: {prob * 100:.2f}%")

        print(f"\nüß† –ù–∏–π—Ç –¥“Ø–≥–Ω—ç–ª—Ç: {best_emotion.upper()} —Å—ç—Ç–≥—ç–ª —Ö”©–¥–ª”©–ª –¥–∞–≤–∞–º–≥–∞–π –±–∞–π–Ω–∞.")
        plot_emotions(emotions, probabilities)